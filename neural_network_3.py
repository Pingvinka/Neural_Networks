# -*- coding: utf-8 -*-
"""Neural_Network_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1va5f-kZ7zm2PCXPArKIydllmXu2QhdCY

Задача регрессии

База данных: образование, результаты экзаменов, Kaggle

#Загрузка данных
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.activations import softmax
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.losses import MAPE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

data = pd.read_csv('/content/Student_Performance.csv')
data

"""#Предобработка данных"""

data.isna().sum() #Проверяю данные на пропуски (в случае появления: если пропусков мало - удали, если много - замени)
not_categorical = {'Yes': 1, 'No': 0}
data['Extracurricular Activities'] = data['Extracurricular Activities'].map(not_categorical) #Убираем категориальные значения
data

X = data.drop('Performance Index', axis=1)
y = data['Performance Index']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#Создание и обучение нейронной сети"""

model = Sequential()
model.add(Dense(128, activation=LeakyReLU(0.8)))
model.add(Dense(64, activation=LeakyReLU(0.5)))
model.add(Dense(1, activation=LeakyReLU(0.5)))

model.compile(optimizer='adam',
              loss = MAPE)

history = model.fit(X_train,
                    y_train,
                    epochs=10,
                    batch_size=32,
                    validation_split=0.2,
                    verbose=1)

plt.plot(history.history['loss'], label = 'Ошибка при обучении')
plt.plot(history.history['val_loss'], label = 'Ошибка при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

"""#Тестирование нейронной сети"""

loss = model.evaluate(X_test, y_test, verbose=0)
print(f"Loss: {loss:.4f}")

new_data = {'Hours Studied': [9, 5, 9],
            'Previous Scores': [100, 76, 23],
            'Extracurricular Activities': [1, 1, 0],
            'Sleep Hours': [8, 12, 3],
            'Sample Question Papers Practiced': [5, 1, 0]}
df = pd.DataFrame(new_data)
df = scaler.transform(df)
a = model.predict(df)
a