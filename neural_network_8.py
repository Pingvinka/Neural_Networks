# -*- coding: utf-8 -*-
"""Neural_Network_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t0nVRk7W-5rAX5Q6DU2yIu4fyPfWb6_6

Реккурентные нейронные сети

Задача: прогнозирование символов

База данных: своя, просто текст

#Загрузка данных
"""

import os
import numpy as np
import re

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.layers import Dense, SimpleRNN, Input
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.saving import save_model, load_model

with open('/content/Belie_nochi.txt', 'r', encoding='utf-8') as f:
    text = f.read()
    text = text.replace('\ufeff', '')
    text = re.sub(r'[^А-я ]', '', text)

"""#Предобработка данных"""

num_characters = 34
tokenizer = Tokenizer(num_words=num_characters, char_level=True)
tokenizer.fit_on_texts([text])
print(tokenizer.word_index)

inp_chars = 8
data = tokenizer.texts_to_matrix(text)
n = data.shape[0] - inp_chars

X = np.array([data[i:i + inp_chars, :] for i in range(n)])
y = data[inp_chars:]

print(data.shape)

"""#Создание и обучение модели"""

model = Sequential()

model.add(Input((inp_chars,
                 num_characters)))
model.add(SimpleRNN(256, activation='tanh'))
model.add(Dense(num_characters, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

callbacks = [EarlyStopping(monitor='loss', patience=5, verbose=1),
             ModelCheckpoint(filepath='best_model8.h5.keras', monitor='loss', save_best_only=True)]

history = model.fit(X, y, batch_size=32, epochs=50, callbacks=callbacks)

"""#Тестирование модели"""

model8 = load_model('best_model8.h5')

def buildPhrase(inp_str, str_len=64):
    for i in range(str_len):
        x = []
        for j in range(i, i + inp_chars):
            x.append(tokenizer.texts_to_matrix(inp_str[j]))

        x = np.array(x)
        inp = x.reshape(1, inp_chars, num_characters)

        pred = model8.predict(inp, verbose=False)
        d = tokenizer.index_word[pred.argmax(axis=1)[0]]

        inp_str += d

    return inp_str

res = buildPhrase('О боже м')
print(res)