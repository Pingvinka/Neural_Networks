# -*- coding: utf-8 -*-
"""Neural_network_12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kxxchc---d0wESr2K1_UpmKqq8d8_gbu

Изи нейросетка для тренировочного этапа в конкурсе

База данных оттуда же

#Загрузка данных
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.activations import softmax
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.optimizers import SGD
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import f1_score

Train = pd.read_csv('/content/08f5db99c83cefe5aa02f41e1e05e0bc.csv')
Need = pd.read_csv('/content/08f5db99c83cefe5aa02f41e1e05e0bc_CaKP56H.csv')

"""#Предобработка данных"""

Need = Need.drop('class', axis=1)
Need = Need.drop('Unnamed: 0', axis=1)
Train = Train.drop('Unnamed: 0', axis=1)
Train.isna().sum() #Пропуски не обнаружены

Train

Need

def not_categorical(value):
    if value == "больше":
      return 5 #Почему именно это значение? Максимальное число в обоих столбцах - 4.
    else:
      return value
Train['doors_count'] = Train['doors_count'].apply(not_categorical)
Train['person_count'] = Train['person_count'].apply(not_categorical)
Need['doors_count'] = Need['doors_count'].apply(not_categorical)
Need['person_count'] = Need['person_count'].apply(not_categorical)
Train

Labels = Train['class']
Data = Train.drop('class', axis = 1)

labels = to_categorical(Labels, num_classes=4)
labels

X_train, X_test, y_train, y_test = train_test_split(Data, labels, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_need = scaler.fit_transform(Need)

np.shape(labels)

"""#Создание и обучение нейронной сети"""

model = Sequential()


model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(BatchNormalization())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))
model.add(LeakyReLU(0.3))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer='adam',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy', 'AUC'])

callbacks = [EarlyStopping(monitor='val_loss', patience=10, verbose=1),
             ModelCheckpoint(filepath='best_model.h5.keras', monitor='val_loss', save_best_only=True)]

# Обучение модели
history = model.fit(X_train,
                    y_train,
                    epochs=250,
                    batch_size=64,
                    validation_split=0.2,
                    verbose=1,
                    callbacks = callbacks)

plt.plot(history.history['AUC'], label = 'Верные ответы при обучении')
plt.plot(history.history['val_AUC'], label = 'Верные ответы при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

"""#Тестирование нейронной сети"""

loss, accuracy, AUC = model.evaluate(X_test, y_test, verbose=0)
print(f"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Auc: {AUC:.4f}")

y_pred = model.predict(X_need)

y_pred

smth = []
for i in range(0, len(y_pred)):
  smth.append(np.argmax(y_pred[i]))
smth

smth = np.asarray(smth)

otvet = pd.Series(smth)

Need['class'] = otvet
Need.to_csv('ОкончательноеРешение.csv', index=False)

Need

"""#Логистическая регрессия"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(Data, Labels, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model_log = LogisticRegression(multi_class='ovr', solver='liblinear', penalty='l1')
model_log.fit(X_train, y_train)

y_pred = model_log.predict(X_test)

y_test = np.asarray(y_test)

accuracy_score(y_pred, y_test)

y_pred

y_test