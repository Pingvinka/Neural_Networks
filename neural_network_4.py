# -*- coding: utf-8 -*-
"""Neural_Network_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13D1jUP8f1Ramm_TTfuNCWPWe8aGGH3m2

Сверточная нейронная сеть

Задача: бинарная классификация изображений

База данных: собаки и кошки, Kaggle

#Загрузка данных
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.activations import softmax
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from pathlib import Path
import os
import os.path

! kaggle datasets download -d erkamk/cat-and-dog-images-dataset

! unzip /content/cat-and-dog-images-dataset.zip

image_dir = Path('/content/Dog and Cat .png')

filepaths = list(image_dir.glob(r'**/*.png'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

image_df = pd.concat([filepaths, labels], axis=1)
image_df

"""# Предобработка данных

"""

train, test = train_test_split(image_df, test_size=0.2, shuffle=True,random_state=1)

#Тут я ещё и генерирую дополнительные данные, чуть-чуть изменяя картинки
train_generator = ImageDataGenerator(rescale=1./255,
                                     validation_split=0.2,
                                     horizontal_flip=True,
                                     width_shift_range=0.2,
                                     height_shift_range=0.2,
                                     rotation_range=10,
                                     zoom_range=0.1
                                     )

train_images = train_generator.flow_from_dataframe(
    dataframe=train,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=True,
    seed=42
)

val_images = train_generator.flow_from_dataframe(
    dataframe=train,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_generator = ImageDataGenerator(rescale=1./255)

test_images = test_generator.flow_from_dataframe(
    dataframe=test,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=False
)

"""# Создание и обучение нейронной сети"""

model = Sequential()

model.add(Conv2D(filters=8, kernel_size =(3,3), activation = 'relu',  input_shape =(224,224,3)))
model.add(MaxPooling2D(2, 2, padding='valid'))

model.add(Conv2D(filters=16, kernel_size =(3,3), activation = 'relu'))
model.add(MaxPooling2D(2, 2, padding='valid'))

model.add(Conv2D(filters=32, kernel_size =(3,3), activation = 'relu'))
model.add(MaxPooling2D(2, 2, padding='valid'))

model.add(Conv2D(filters=64, kernel_size =(3,3), activation = 'relu'))
model.add(MaxPooling2D(2, 2, padding='valid'))

model.add(Flatten())

model.add(Dense(128, activation = 'relu'))
model.add(Dense(64, activation = 'relu'))

model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam',
              loss = 'binary_crossentropy',
              metrics = ['Accuracy'])

callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=1),
             ModelCheckpoint(filepath='best_model1.h5', monitor='val_loss', save_best_only=True)]

history = model.fit(train_images,
                    epochs=20,
                    batch_size=32,
                    verbose=1,
                    validation_data=val_images,
                    callbacks=callbacks)

plt.plot(history.history['loss'], label = 'Ошибка при обучении')
plt.plot(history.history['val_loss'], label = 'Ошибка при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

plt.plot(history.history['Accuracy'], label = 'Верные ответы при обучении')
plt.plot(history.history['val_Accuracy'], label = 'Верные ответы при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

model.save('best_model41.h5')

"""#Трансферное обучение"""

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
output = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers:
    layer.trainable = False
model.summary()

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1),
             ModelCheckpoint(filepath='best_model4.h5', monitor='val_loss', save_best_only=True)]

history = model.fit(train_images,
                    epochs=5,
                    batch_size=32,
                    verbose=1,
                    validation_data=val_images,
                    callbacks=callbacks)

model.save('best_model42.h5')

"""# Тестирование нейронной сети"""

model4 = keras.models.load_model('best_model4.h5')

loss, accuracy = model4.evaluate(test_images, verbose=0)
print(f"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}")