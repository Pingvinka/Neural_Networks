# -*- coding: utf-8 -*-
"""Neural_Network_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gTprKLQhr54X-T71Rvlj-yp-2c3G-xqO

Сверточная нейронная сеть

Задача: многоклассовая классификация изображений

База данных: эмоции человека, Kaggle

#Загрузка данных
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import VGG16, VGG19, ResNet50
from pathlib import Path
import os
import os.path

! kaggle datasets download -d sanidhyak/human-face-emotions

! unzip /content/human-face-emotions.zip

image_dir = Path('/content/data')

filepaths = list(image_dir.glob(r'**/*.*'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

data = pd.concat([filepaths, labels], axis=1)
data

"""#Предобработка данных"""

train_and_val, test = train_test_split(data, test_size=0.2, shuffle=True, random_state=42)

train, valid = train_test_split(train_and_val, test_size=0.2, shuffle=True, random_state=42)

train_generator = ImageDataGenerator(rescale=1./255,
                                     validation_split=0.2,
                                     horizontal_flip=True,
                                     width_shift_range=0.2,
                                     height_shift_range=0.2,
                                     rotation_range=10,
                                     zoom_range=0.1
                                     )

train_images = train_generator.flow_from_dataframe(
    dataframe=train,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42
)

val_generator = ImageDataGenerator(rescale=1./255)

val_images = train_generator.flow_from_dataframe(
    dataframe=valid,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42
)

test_generator = ImageDataGenerator(rescale=1./255)

test_images = test_generator.flow_from_dataframe(
    dataframe=test,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

"""#Создание и обучение нейронной сети"""

model = Sequential()

model.add(Conv2D(16, (3,3), input_shape=(224, 224, 3)))
model.add(MaxPooling2D())

model.add(Conv2D(32, (3,3)))
model.add(MaxPooling2D())

model.add(Conv2D(64, (3,3)))
model.add(MaxPooling2D())

model.add(Conv2D(128, (2,2)))
model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(128, activation = 'relu'))
model.add(Dropout(0.6))
model.add(Dense(64, activation = 'relu'))
model.add(Dense(3, activation = 'softmax'))

model.summary()

model.compile(optimizer='adam',
              loss = 'categorical_crossentropy',
              metrics = ['Accuracy', 'AUC'])

callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=1),
             ModelCheckpoint(filepath='best_model5.h5', monitor='val_loss', save_best_only=True)]

history = model.fit(train_images,
                    epochs=10,
                    batch_size=32,
                    verbose=1,
                    validation_data=val_images,
                    callbacks=callbacks)

plt.plot(history.history['loss'], label = 'Ошибка при обучении')
plt.plot(history.history['val_loss'], label = 'Ошибка при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

plt.plot(history.history['Accuracy'], label = 'Верные ответы при обучении')
plt.plot(history.history['val_Accuracy'], label = 'Верные ответы при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

plt.plot(history.history['auc'], label = 'Верные ответы при обучении')
plt.plot(history.history['val_auc'], label = 'Верные ответы при проверке')
plt.xlabel('эпоха')
plt.ylabel('верные ответы')
plt.legend()
plt.show()

"""#Трансферное обучение"""

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.7)(x)
output = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers[-4:]: #Размараживаю 4 последних слоя
    layer.trainable = False
model.summary()

#Показательно буду использовать Vgg16 и Vgg19, они записаны слегка в разных формах (чтобы показать, что можно по-разному инициализировать модели)
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3), classes=3)
x = base_model.output
x = Dense(512, activation='relu')(x)
output = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers:
    layer.trainable = False

model.summary()

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.7)(x)
output = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

for layer in base_model.layers:
    layer.trainable = False
model.summary()

model.compile(optimizer='adam',
              loss = 'categorical_crossentropy',
              metrics = ['Accuracy', 'AUC'])

callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1),
             ModelCheckpoint(filepath='best_model5.h5', monitor='val_loss', save_best_only=True)]

history = model.fit(train_images,
                    epochs=15,
                    batch_size=32,
                    verbose=1,
                    validation_data=val_images,
                    callbacks=callbacks)

"""#Тестирование нейронной сети"""

model5 = keras.models.load_model('best_model5.h5')

loss, accuracy, auc = model5.evaluate(test_images, verbose=0)
print(f"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {auc:.4f}")